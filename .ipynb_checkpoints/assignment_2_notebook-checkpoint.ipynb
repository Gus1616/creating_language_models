{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d213bb83",
   "metadata": {},
   "source": [
    "1. Choose 10 words from your corpus and see what words are considered to be the most similar\n",
    "using the pre-trained word2vec introduced in Task 1 of Workshop 4. Discuss and briefly\n",
    "document the outputs, keeping in mind that the pre-trained word2vec is only a sample model.\n",
    "You may look at other pre-trained models but this is not compulsory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79e9355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import string\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "from nltk.lm import MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aa5bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package word2vec_sample to\n",
      "[nltk_data]     C:\\Users\\gusbo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('word2vec_sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a639bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.data import find\n",
    "word2vec_sample = str(find('models/word2vec_sample/pruned.word2vec.txt'))\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_sample, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bbf3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(model.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847d4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = list(model.wv.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a02deb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrds = ['boss', 'American', 'house', 'deposit', 'insult', 'ban', 'tax','jokes', 'crying', 'Asylum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a5eaf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boss  =  [('bosses', 0.6286454200744629), ('exec', 0.5187475085258484), ('manager', 0.5121563673019409)]\n",
      "American  =  [('America', 0.6116390228271484), ('U.S.', 0.5309481620788574), ('Americans', 0.5179345607757568)]\n",
      "house  =  [('houses', 0.7072389721870422), ('bungalow', 0.6878559589385986), ('apartment', 0.6628994941711426)]\n",
      "deposit  =  [('deposits', 0.8111315965652466), ('deposited', 0.4882561266422272), ('bank', 0.48702573776245117)]\n",
      "insult  =  [('insulting', 0.5839250683784485), ('affront', 0.5768641233444214), ('insulted', 0.5377302169799805)]\n",
      "ban  =  [('bans', 0.875502347946167), ('banning', 0.8072464466094971), ('prohibition', 0.7315009236335754)]\n",
      "tax  =  [('taxes', 0.8404221534729004), ('Tax', 0.7688615918159485), ('taxation', 0.6788967847824097)]\n",
      "jokes  =  [('joke', 0.7732844352722168), ('gags', 0.7269544005393982), ('laughs', 0.6667405962944031)]\n",
      "crying  =  [('sobbing', 0.7245960235595703), ('bawling', 0.7186652421951294), ('cried', 0.7152251601219177)]\n",
      "Asylum  =  [('Detention', 0.42114198207855225), ('Atomic', 0.37061551213264465), ('Salvation', 0.3705124855041504)]\n"
     ]
    }
   ],
   "source": [
    "for i in wrds:\n",
    "    print(i,  \" = \", model.most_similar(i, topn = 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8676bd",
   "metadata": {},
   "source": [
    "#### Looking at other pre trained models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f214e683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901aff1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0396d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c59115b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a87851d7",
   "metadata": {},
   "source": [
    "2. Using the tools introduced in Task 4 of Workshop 4, build a language model for your corpus\n",
    "and discuss some of the “sentences” that can be generated from this language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92f763f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_txt(file):\n",
    "    with open(file) as f:\n",
    "        return ' '.join(line.strip() for line in f.readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04ca85f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (3449460270.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\gusbo\\AppData\\Local\\Temp\\ipykernel_21636\\3449460270.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    r/ireland = load_txt('ireland.txt')\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "r/ireland = load_txt('ireland.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273bed9",
   "metadata": {},
   "source": [
    "3. Using the tools of Task 4 of Workshop 4 now build a model for words (letter n-grams) rather\n",
    "than sentences for all words in your corpus which begin with the same letter as your surname1\n",
    ".\n",
    "Note that you will need to prepare the data differently for this. Discuss some of the “words” that\n",
    "can be generated from this language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a810e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810a529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cceed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07593dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
